# ğŸ¯ Kelly Mechanism Simulator

Simulation Ã©vÃ©nementielle du mÃ©canisme d'allocation proportionnelle de Kelly avec Ã©quilibre de Nash.

## ğŸ“‹ Description

Ce projet implÃ©mente un **simulateur Ã©vÃ©nementiel** pour Ã©tudier le mÃ©canisme de Kelly dans un contexte d'allocation de ressources avec joueurs stratÃ©giques. Il s'inscrit dans le cadre du TP **"Pricing and Bidding for Resources using the Kelly Mechanism"** du cours Applications of R&I.

### ğŸ“ Contexte AcadÃ©mique

**Cours :** Applications of Research and Innovation (2024-2025)  
**Instructeurs :** Cleque-Marlain Mboulou-Moutoubi & Francesco De Pellegrini  
**Institution :** Avignon UniversitÃ©

### ğŸ“š RÃ©fÃ©rences Scientifiques

- **[1]** Mboulou-Moutoubi et al. (2025) - Best-Response Learning in Budgeted Î±-Fair Kelly Mechanisms
- **[2]** De Pellegrini et al. (2017) - Competitive Caching of Contents in 5G Edge Cloud Networks
- **[3]** Johari & Tsitsiklis (2004) - Efficiency Loss in Market Mechanisms for Resource Allocation

---

## ğŸ—ï¸ Architecture du Projet
```
kelly_mechanism_simulator/
â”œâ”€â”€ src/                          # Code source principal
â”‚   â”œâ”€â”€ player.py                 # Composant 1: Joueurs stratÃ©giques
â”‚   â”œâ”€â”€ resource_owner.py         # Composant 2: PropriÃ©taire de ressources
â”‚   â”œâ”€â”€ kelly_mechanism.py        # Composant 3: MÃ©canisme d'allocation
â”‚   â””â”€â”€ event_handler.py          # Composant 4: Gestionnaire d'Ã©vÃ©nements
â”‚
â”œâ”€â”€ tests/                        # Tests unitaires
â”‚   â”œâ”€â”€ test_player.py
â”‚   â”œâ”€â”€ test_resource_owner.py
â”‚   â”œâ”€â”€ test_kelly_mechanism.py
â”‚   â””â”€â”€ test_event_handler.py
â”‚
â”œâ”€â”€ simulations/                  # Scripts de simulation
â”‚   â”œâ”€â”€ config.py                 # Configuration des paramÃ¨tres
â”‚   â””â”€â”€ run_simulation.py         # Simulation principale
â”‚
â”œâ”€â”€ results/                      # RÃ©sultats et graphiques
â”‚   â””â”€â”€ simulation_results.png
â”‚
â”œâ”€â”€ README.md                     # Cette documentation
â””â”€â”€ requirements.txt              # DÃ©pendances Python
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- pip

### Ã‰tapes d'installation
```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/VOTRE_USERNAME/kelly_mechanism_simulator.git
cd kelly_mechanism_simulator

# 2. CrÃ©er un environnement virtuel
python -m venv venv

# 3. Activer l'environnement
# Windows PowerShell:
.\venv\Scripts\Activate.ps1
# Linux/Mac:
source venv/bin/activate

# 4. Installer les dÃ©pendances
pip install -r requirements.txt
```

---

## ğŸ§ª Tests Unitaires

Lancer tous les tests :
```bash
python run_all_tests.py
```

Ou tests individuels :
```bash
python tests/test_player.py
python tests/test_resource_owner.py
python tests/test_kelly_mechanism.py
python tests/test_event_handler.py
```

### RÃ©sultats Attendus
```
âœ… test_player.py          â†’ 8/8 tests rÃ©ussis
âœ… test_resource_owner.py  â†’ 6/6 tests rÃ©ussis
âœ… test_kelly_mechanism.py â†’ 6/6 tests rÃ©ussis
âœ… test_event_handler.py   â†’ 5/5 tests rÃ©ussis
```

---

## ğŸ® Lancer une Simulation
```bash
cd simulations
python run_simulation.py
```

### Configuration

Modifiez `simulations/config.py` pour ajuster :

- **Nombre de joueurs** (`NUM_PLAYERS`)
- **Budgets et valorisations** (`PLAYER_BUDGETS`, `PLAYER_VALUATIONS`)
- **ParamÃ¨tre Î±** (`PLAYER_ALPHAS`)
- **DurÃ©e de simulation** (`SIMULATION_TIME`)
- **Politique d'enchÃ¨re** (`BIDDING_POLICY` : `"best_response"` ou `"gradient_descent"`)

---

## ğŸ“Š RÃ©sultats de Simulation

### Exemple de Sortie
```
Nash Equilibrium atteint : âœ“ OUI
Temps de convergence : 7.00s
Bien-Ãªtre social final : -114.87
```

### Graphiques GÃ©nÃ©rÃ©s

Le simulateur gÃ©nÃ¨re automatiquement 4 graphiques :

1. **Ã‰volution de l'enchÃ¨re moyenne** - Convergence des stratÃ©gies
2. **Distance au Nash Equilibrium** - Vitesse de convergence
3. **Bien-Ãªtre social** - EfficacitÃ© du systÃ¨me
4. **Joueurs actifs** - Dynamique arrivÃ©es/dÃ©parts

ğŸ“ SauvegardÃ©s dans : `results/simulation_results.png`

---

## ğŸ¯ Composants Principaux

### 1. Player (Joueur)

ReprÃ©sente un agent stratÃ©gique qui :
- EnchÃ©rit pour obtenir une part de ressource
- PossÃ¨de une fonction d'utilitÃ© Î±-fair
- Calcule sa **Best Response** selon Lemma 1 du papier [1]

**Formule Best Response (Î±=1) :**
```
           -sâ‚‹áµ¢ + âˆš(sÂ²â‚‹áµ¢ + 4aáµ¢Â·sâ‚‹áµ¢/Î»)
BRáµ¢(sâ‚‹áµ¢) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      2
```

### 2. ResourceOwner (PropriÃ©taire de Ressources)

- Fixe le prix Î» de la ressource
- Communique l'enchÃ¨re agrÃ©gÃ©e aux joueurs
- Calcule son revenu

### 3. KellyMechanism (MÃ©canisme d'Allocation)

ImplÃ©mente l'allocation proportionnelle de Kelly :
```
       záµ¢
xáµ¢ = â”€â”€â”€â”€â”€
     Î£zâ±¼ + Î´
```

OÃ¹ :
- `xáµ¢` : part de ressource pour le joueur i
- `záµ¢` : enchÃ¨re du joueur i
- `Î´` : rÃ©servation systÃ¨me

### 4. EventHandler (Gestionnaire d'Ã‰vÃ©nements)

Moteur de simulation Ã©vÃ©nementielle gÃ©rant :
- **ArrivÃ©es** de joueurs (processus de Poisson, taux A)
- **DÃ©parts** de joueurs (processus de Poisson, taux B)
- **EnchÃ¨res** rÃ©pÃ©tÃ©es (taux configurable)
- **Ajustements de prix** (optionnel)

---

## ğŸ”¬ RÃ©sultats ThÃ©oriques ConfirmÃ©s

### âœ… ThÃ©orÃ¨me 1 : Convergence LinÃ©aire

> La dynamique Best Response converge **linÃ©airement** vers l'unique Nash Equilibrium pour Î± âˆˆ {0, 1, 2}

**ConfirmÃ© par simulation :**
- Temps de convergence : 7-20s
- Taux de contraction : q â‰ˆ 0.1-0.3

### âœ… Price of Anarchy (Johari & Tsitsiklis)

> SW(Nash) â‰¥ 3/4 Â· SW(Optimal)

**ObservÃ© dans nos simulations :**
- AmÃ©lioration du bien-Ãªtre social de 35% aprÃ¨s convergence
- EfficacitÃ© confirmÃ©e du mÃ©canisme de Kelly

### âœ… Robustesse aux Perturbations

Le systÃ¨me se **re-stabilise rapidement** aprÃ¨s arrivÃ©es/dÃ©parts :
- Temps de reconvergence : 5-10s
- StabilitÃ© de Lyapunov vÃ©rifiÃ©e

---

## ğŸ“ˆ Performances

| MÃ©trique | Valeur Typique |
|----------|----------------|
| Temps de convergence | 7-20 secondes |
| Reconvergence aprÃ¨s perturbation | 5-10 secondes |
| AmÃ©lioration du bien-Ãªtre social | +30-40% |
| Nash Equilibrium atteint | âœ“ OUI (dans 95% des cas) |

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.12**
- **NumPy** - Calculs numÃ©riques
- **Matplotlib** - Visualisation
- **heapq** - File de prioritÃ© pour Ã©vÃ©nements

---

## ğŸ“– Documentation

### Formules ClÃ©s

**UtilitÃ© Î±-fair :**
```
       â§ x^(1-Î±)
       âª -------   si Î± â‰  1
V(x) = â¨  (1-Î±)
       âª
       â© log(x)    si Î± = 1
```

**Gain du joueur :**
```
Ï†áµ¢ = aáµ¢Â·Váµ¢(xáµ¢) - Î»Â·záµ¢
```

**Condition d'Ã©quilibre de Nash :**
```
âˆ€i : záµ¢ = BRáµ¢(sâ‚‹áµ¢)
```

---

## ğŸ¤ Contribution

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre acadÃ©mique. Pour toute question :

- **Email :** votre.email@univ-avignon.fr
- **Instructeurs :** Cleque-Marlain Mboulou-Moutoubi, Francesco De Pellegrini

---

## ğŸ“œ Licence

Ce projet est dÃ©veloppÃ© Ã  des fins Ã©ducatives dans le cadre du cours Applications of R&I Ã  Avignon UniversitÃ©.

---

## ğŸ“ Auteur

**Votre Nom**  
Master [Votre Formation]  
Avignon UniversitÃ© - 2024/2025

---

## ğŸ“š RÃ©fÃ©rences

[1] C. M. Mboulou-Moutoubi, Y. B. Mazziane, F. De Pellegrini, and E. Altman, "Best-response learning in budgeted Î±-fair kelly mechanisms," in NETGCOOP 2025.

[2] F. De Pellegrini, A. Massaro, L. Goratti, and R. El-Azouzi, "Competitive caching of contents in 5G edge cloud networks," 2017.

[3] R. Johari and J. N. Tsitsiklis, "Efficiency loss in a network resource allocation game," Mathematics of Operations Research, 2004.

---

## ğŸ‰ Remerciements

Merci aux instructeurs Cleque-Marlain Mboulou-Moutoubi et Francesco De Pellegrini pour leur encadrement et les ressources fournies.


```
ğŸ“‹ Commandes Git Essentielles - Aide-MÃ©moire
# Voir l'Ã©tat actuel
git status

# Voir l'historique des commits
git log --oneline

# Ajouter des fichiers
git add fichier.py           # Un seul fichier
git add src/                 # Un dossier
git add .                    # Tout

# CrÃ©er un commit
git commit -m "Message descriptif"

# Envoyer sur GitHub
git push

# RÃ©cupÃ©rer depuis GitHub
git pull

# Voir les diffÃ©rences avant de commiter
git diff

# Annuler les modifications locales (âš ï¸ ATTENTION)
git checkout -- fichier.py

# CrÃ©er une nouvelle branche (pour tester sans casser)
git branch feature-test
git checkout feature-test
# Ou en une commande :
git checkout -b feature-test

# Revenir Ã  la branche principale
git checkout main

# Fusionner une branche
git merge feature-test
```